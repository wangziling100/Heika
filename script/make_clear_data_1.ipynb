{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the initial data is already cleared according to their length and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from minisom import MiniSom\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ability_level_mapper(data, groups=None, col='front', how='naive', n_level=19, invert=True,\n",
    "                         parameters=None,target_col_name='performance'):\n",
    "    # the raw data is divided into groups according to its exc_num, ability levels are calculated respectively\n",
    "    # how: 1 is mapping without any other processing, called 'naive'\n",
    "    origin = data.copy()\n",
    "    \n",
    "    if parameters is not None:\n",
    "        col, how, n_level, invert, v_max, v_min = parameters\n",
    "        interval = (v_max- v_min)/n_level\n",
    "        assert interval!=0, 'zero dividend'\n",
    "        origin[target_col_name] = (origin[col]-v_min)/interval\n",
    "        \n",
    "        origin[target_col_name] = origin[target_col_name].astype(int)\n",
    "        if invert:\n",
    "            origin[target_col_name] = n_level-origin[target_col_name]+1\n",
    "        else:\n",
    "            origin[target_col_name] = origin[target_col_name]+1\n",
    "        \n",
    "        return origin, parameters\n",
    "        \n",
    "    if groups == None:\n",
    "        v_max = origin[col].max()\n",
    "        v_min = origin[col].min()\n",
    "        \n",
    "        interval = (v_max- v_min)/n_level\n",
    "        assert interval!=0, 'zero dividend'\n",
    "        origin[target_col_name] = (origin[col]-v_min)/interval\n",
    "        \n",
    "        origin[target_col_name] = origin[target_col_name].astype(int)\n",
    "        if invert:\n",
    "            origin[target_col_name] = n_level-origin[target_col_name]+1\n",
    "        else:\n",
    "            origin[target_col_name] = origin[target_col_name]+1\n",
    "        \n",
    "        parameters = (col, how, n_level, invert, v_max, v_min )\n",
    "        return origin, parameters\n",
    "    \n",
    "    if how == 1 or how=='naive':\n",
    "        tmp = origin[col]\n",
    "        for index, group in groups:\n",
    "            \n",
    "            v_max = group[col].max()\n",
    "            v_min = group[col].min()\n",
    "            \n",
    "            interval = (v_max-v_min)/n_level\n",
    "            \n",
    "            assert interval!=0, 'zero dividend'\n",
    "            \n",
    "            origin.loc[index, col] = (origin.loc[index, col]-v_min)/interval\n",
    "        origin[col] = origin[col].astype(int)\n",
    "        if invert:\n",
    "            origin[target_col_name] = n_level-origin[col]+1\n",
    "            \n",
    "        else:\n",
    "            origin[target_col_name] = origin[target_col_name]+1\n",
    "        origin[col] = tmp\n",
    "        parameters = (col, how, n_level, invert, v_max, v_min )\n",
    "        del tmp\n",
    "        return origin, parameters\n",
    "\n",
    "def calc_force(df):\n",
    "    df['force'] = df['Fx']**2 + df['Fy']**2 + df['Fz']**2\n",
    "    df['force'] = df['force'].pow(1/2)\n",
    "    return df\n",
    "\n",
    "def calc_resultent_force(df):\n",
    "    # calc resultent force\n",
    "    df['resultent_force'] = (df['Fx']-df['Fx.1'])**2+(df['Fy']-df['Fy.1'])**2+(df['Fz']-df['Fz.1'])**2\n",
    "    df['resultent_force'] = df['resultent_force'].pow(1/2)\n",
    "    return df\n",
    "\n",
    "def calc_resultent_force_xy(df):\n",
    "    # calc resultent force on flat xoy\n",
    "    df['resultent_force_xy'] = (df['Fx']-df['Fx.1'])**2+(df['Fy']-df['Fy.1'])**2\n",
    "    df['resultent_force_xy'] = df['resultent_force_xy'].pow(1/2)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_velocity(df):\n",
    "    df['velocity'] = df['Lx']**2 + df['Ly']**2 + df['Lz']**2\n",
    "    df['velocity'] = df['velocity'].pow(1/2)\n",
    "    return df\n",
    "\n",
    "def calc_velocity_xy(df):\n",
    "    df['velocity_xy'] = df['Lx']**2 + df['Ly']**2\n",
    "    df['velocity_xy'] = df['velocity_xy'].pow(1/2)\n",
    "    return df\n",
    "\n",
    "def calc_force_velocity_angle_xy(df):\n",
    "    # calculate angle between walk direction and force direction\n",
    "    if 'resultent_force_xy' not in df.columns:\n",
    "        df = calc_resultent_force_xy(df)\n",
    "        \n",
    "    if 'velocity_xy' in df.columns: \n",
    "        df = calc_velocity_xy(df)\n",
    "    \n",
    "    df['angle_fv_xy'] = ((df['Fx']-df['Fx.1'])*df['Lx']+(df['Fy']-df['Fy.1'])*df['Ly'])/  \\\n",
    "        (df['velocity_xy']*df['resultent_force_xy'])\n",
    "    df['angle_fv_xy'] = df['angle_fv_xy'].apply(np.arccos)\n",
    "    tmp = df['angle_fv_xy'][df['angle_fv_xy']>np.pi/2]\n",
    "    tmp -= np.pi\n",
    "    \n",
    "    # here is maybe a bug\n",
    "    df.loc[df.angle_fv_xy>np.pi/2, 'angle_fv_xy'] = tmp\n",
    "    del tmp\n",
    "    return df\n",
    "\n",
    "def calc_torque_xy(df, threshold=0):\n",
    "    df['torque_xy'] = df['Mz']-df['Mz.1']\n",
    "    return df\n",
    "\n",
    "def calc_torque_xy_avg(df, threshold=0, n=100, dropna=True):\n",
    "    print('torque')\n",
    "    print(len(df))\n",
    "    if 'torque_xy' not in df.columns:\n",
    "        df = calc_torque_xy(df)\n",
    "        \n",
    "    df['torque_xy_avg'] = df.groupby(['uid','day','exc_num', 'exc_times'])['torque_xy'].\\\n",
    "        rolling(n).mean().reset_index()['torque_xy']\n",
    "        \n",
    "    if threshold!=0:\n",
    "        assert threshold>0, 'threshold must be positive'\n",
    "        df[(df.torque_xy_avg<threshold) & (df.torque_xy_avg>-threshold)] = 1\n",
    "        df[df.torque_xy_avg<=-threshold] = 0\n",
    "        df[df.torque_xy_avg>=threshold] = 2\n",
    "        \n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "    print(len(df.dropna()))\n",
    "    return df\n",
    "\n",
    "def calc_abs_force_velocity_angle_xy(df):\n",
    "    # calculate absolute angle between walk direction and force direction\n",
    "    if 'resultent_force_xy' not in df.columns:\n",
    "        df = calc_resultent_force_xy(df)\n",
    "        \n",
    "    if 'velocity_xy' in df.columns: \n",
    "        df = calc_velocity_xy(df)\n",
    "    \n",
    "    df['abs_angle_fv_xy'] = ((df['Fx']-df['Fx.1'])*df['Lx']+(df['Fy']-df['Fy.1'])*df['Ly'])/  \\\n",
    "        (df['velocity_xy']*df['resultent_force_xy'])\n",
    "    df['abs_angle_fv_xy'] = abs(df['abs_angle_fv_xy'])\n",
    "    df['abs_angle_fv_xy'] = df['abs_angle_fv_xy'].apply(np.arccos)\n",
    "    return df\n",
    "\n",
    "def calc_torque_turning_freq(df,interval=100, groups=None):\n",
    "    # calculate the frequency of the changing of the direction of the torque on flat xoy\n",
    "    result = pd.Series()\n",
    "    if 'torque_xy' not in df.columns:\n",
    "        df = calc_torque_xy(df)\n",
    "    if groups == None:\n",
    "        groups = df[['uid', 'day', 'exc_num', 'exc_times', 'torque_xy']].   \\\n",
    "            groupby(['uid', 'day', 'exc_num', 'exc_times'])\n",
    "        \n",
    "    for index, group in groups:\n",
    "        # calculate the direction of the changing of the values\n",
    "        df_tmp = group.reset_index()\n",
    "        df_tmp['tt_freq'] = df_tmp['torque_xy']\n",
    "        df_tmp.loc[0, 'tt_freq'] = 0\n",
    "        tmp1 = df_tmp['torque_xy'][:-1].reset_index(drop=True)\n",
    "        tmp2 = df_tmp['torque_xy'][1:].reset_index(drop=True)\n",
    "\n",
    "        tmp3 = tmp2-tmp1\n",
    "        tmp3.index = tmp3.index+1\n",
    "        df_tmp.loc[1:, 'tt_freq'] = tmp3\n",
    "\n",
    "        # delete 0 value, and compare two adjecend value, if the direction changes, then the product is negative.\n",
    "        tmp3 = df_tmp[df_tmp['tt_freq']!=0][['tt_freq']]\n",
    "        tmp3 = tmp3.reset_index()\n",
    "        tmp1 = tmp3['tt_freq'][:-1].reset_index()\n",
    "        tmp2 = tmp3['tt_freq'][1:].reset_index()\n",
    "        tmp4 = tmp1*tmp2\n",
    "        tmp4.index += 1\n",
    "        tmp3[0, 'tt_freq'] = 0\n",
    "        tmp3.loc[1:, 'tt_freq'] = tmp4\n",
    "        tmp3.index = tmp3['index']\n",
    "        df_tmp.loc[df_tmp.tt_freq!=0, 'tt_freq'] = tmp3['tt_freq']\n",
    "\n",
    "        # count in interval\n",
    "        df_tmp.loc[df_tmp.tt_freq>=0, 'tt_freq'] = np.nan\n",
    "        df_tmp['tt_freq'] = df_tmp['tt_freq'].rolling(interval).count()\n",
    "        df_tmp.index = df_tmp['index']\n",
    "        result = pd.concat([result, df_tmp['tt_freq']])\n",
    "        del tmp1\n",
    "        del tmp2\n",
    "        del tmp3\n",
    "        del tmp4\n",
    "#     print(result)\n",
    "    # index aligning\n",
    "    df['tt_freq'] = result\n",
    "#     print(all_data[['torque_xy','tt_freq']])\n",
    "    del result\n",
    "    return df   \n",
    "\n",
    "def calc_abs_angle_rotation_velocity_xy(df, groups=None):\n",
    "    # calculate relative absolute angle rotation of velocity on flat xoy\n",
    "    \n",
    "    if 'velocity_xy' not in df.columns:\n",
    "        df = calc_velocity_xy(df)\n",
    "        \n",
    "    result = pd.Series()\n",
    "    if groups == None:\n",
    "        groups = df[['uid', 'day', 'exc_num', 'exc_times', 'Lx', 'Ly', 'velocity_xy']].   \\\n",
    "            groupby(['uid', 'day', 'exc_num', 'exc_times'])\n",
    "        \n",
    "    for index, group in groups:\n",
    "        # calculate angle rotation from two adjecend time point\n",
    "        df_tmp = group.reset_index()\n",
    "        df_tmp['v_rotation'] = 0\n",
    "        tmp1 = df_tmp.loc[0:len(df_tmp)-2, ['Lx', 'Ly', 'velocity_xy']].reset_index(drop=True)\n",
    "        tmp2 = df_tmp.loc[1:, ['Lx', 'Ly', 'velocity_xy']].reset_index(drop=True)\n",
    "    \n",
    "        tmp3 = (tmp1['Lx']*tmp2['Lx']+tmp1['Ly']*tmp2['Ly'])/  \\\n",
    "        (tmp1['velocity_xy']*tmp2['velocity_xy'])\n",
    "#         tmp3 = tmp3.fillna(0)\n",
    "#         print(tmp3)\n",
    "        tmp3 = tmp3.apply(np.arccos)\n",
    "#         print(tmp3)\n",
    "        tmp3.index += 1\n",
    "        df_tmp.loc[1:, 'v_rotation'] = tmp3\n",
    "        df_tmp.loc[df_tmp.v_rotation>np.pi/2, 'v_rotation'] -= np.pi\n",
    "        df_tmp.loc[df_tmp.v_rotation<0.0001, 'v_rotation'] = 0\n",
    "        df_tmp['v_rotation'] = df_tmp['v_rotation'].fillna(0)\n",
    "#         print(df_tmp.loc[:, ['v_rotation', 'Lx', 'Ly']])\n",
    "        \n",
    "        df_tmp.index = df_tmp['index']\n",
    "        result = pd.concat([result, df_tmp['v_rotation']])\n",
    "        del tmp1\n",
    "        del tmp2\n",
    "        del tmp3\n",
    "        del df_tmp\n",
    "    df['v_abs_rotation'] = result\n",
    "    del result\n",
    "    return df\n",
    "\n",
    "def calc_angle_rotation_velocity_xy(df, groups=None):\n",
    "    # calculate relative angle rotation of velocity on flat xoy\n",
    "    \n",
    "    if 'velocity_xy' not in df.columns:\n",
    "        df = calc_velocity_xy(df)\n",
    "        \n",
    "    result = pd.Series()\n",
    "    if groups == None:\n",
    "        groups = df[['uid', 'day', 'exc_num', 'exc_times', 'Lx', 'Ly', 'velocity_xy']].   \\\n",
    "            groupby(['uid', 'day', 'exc_num', 'exc_times'])\n",
    "        \n",
    "    for index, group in groups:\n",
    "        # calculate angle rotation from two adjecend time point\n",
    "        df_tmp = group.reset_index()\n",
    "        df_tmp['v_rotation'] = 0\n",
    "#         tmp1 = df_tmp['Ly']/df_tmp['Lx']\n",
    "        tmp1 = np.arctan2(df_tmp['Ly'], df_tmp['Lx'])\n",
    "        tmp2 = tmp1[1:].reset_index(drop=True) - tmp1[:-1].reset_index(drop=True)\n",
    "\n",
    "        tmp2.index += 1\n",
    "        df_tmp.loc[1:, 'v_rotation'] = tmp2\n",
    "        df_tmp['v_rotation'] = df_tmp['v_rotation'].fillna(0)\n",
    "#         print(df_tmp.loc[:, ['v_rotation', 'Lx', 'Ly']])\n",
    "        \n",
    "        df_tmp.index = df_tmp['index']\n",
    "        result = pd.concat([result, df_tmp['v_rotation']])\n",
    "        del tmp1\n",
    "        del tmp2\n",
    "        del df_tmp\n",
    "    df['v_rotation'] = result\n",
    "    df.loc[df.v_rotation<-np.pi, 'v_rotation'] += 2*np.pi\n",
    "    df.loc[df.v_rotation>np.pi, 'v_rotation'] -= 2*np.pi\n",
    "    del result\n",
    "    return df\n",
    "\n",
    "def calc_velocity_angle(df):\n",
    "#     tan = df['Ly']/df['Lx']\n",
    "    df['v_angle'] = np.arctan2(df['Ly'], df['Lx'])\n",
    "#     del tan\n",
    "    return df\n",
    "\n",
    "def calc_sd_velocity(df, n=20, dropna=True):\n",
    "    print('sd')\n",
    "    print(len(df))\n",
    "    if 'velocity' not in df.columns:\n",
    "        df = calc_velocity(df)\n",
    "    df['v_sd'] = df.groupby(['uid','day','exc_num', 'exc_times'])['velocity'].\\\n",
    "        rolling(n).std().reset_index()['velocity']\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "    print(len(df.dropna()))\n",
    "    return df\n",
    "\n",
    "def calc_avg_velocity(df, interval=100):\n",
    "    if 'velocity' not in df.columns:\n",
    "        df = calc_velocity(df)\n",
    "        \n",
    "    df['avg_velocity'] = df.groupby(['uid','day','exc_num', 'exc_times'])['velocity'].\\\n",
    "        rolling(interval).mean().reset_index()['velocity']\n",
    "    return df\n",
    "\n",
    "def calc_velocity_deviation_score(df, a=0.01):\n",
    "    if 'avg_velocity' not in df.columns:\n",
    "        df = calc_avg_velocity(df)\n",
    "        \n",
    "    df['vd_score'] = df['avg_velocity']/(a+df['front'])\n",
    "    return df\n",
    "\n",
    "def del_outlier(df, by, test_col, threshold=10):\n",
    "    \n",
    "    # assume that the distribution of test column in each group are normal, \n",
    "    # the data outside 2 standard deviation are considered as outlier.\n",
    "    # the data with too few samples will be deleted\n",
    "    \n",
    "    cols = df.columns\n",
    "    # delete data with a few samples\n",
    "    count = df[by+[test_col]].groupby(by).count()\n",
    "    count = count[count[test_col]>threshold].reset_index()\n",
    "    count = count[by]\n",
    "    df = df.merge(count, on=by)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # delete outlier\n",
    "    mean = df[by+[test_col]].groupby(by).mean()\n",
    "    std = df[by+[test_col]].groupby(by).std()\n",
    "    left = mean-2*std\n",
    "    right = mean+2*std\n",
    "    left = left.reset_index()\n",
    "    right = right.reset_index()\n",
    "    left.columns = by+['left']\n",
    "    right.columns = by+['right']\n",
    "    \n",
    "    df = df.merge(left, on=by)\n",
    "    df = df.merge(right, on=by)\n",
    "    df['left'] = df[test_col]-df['left']\n",
    "    df['right'] = df[test_col] - df['right']\n",
    "    df = df[(df['left'])>0 & (df['right']<0)]\n",
    "    df = df[cols]\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def set_inverted_task(df, tasks=[2.4, 3.4, 4.1, 4.2, 4.3]):\n",
    "    df['inverted'] = 0\n",
    "    for task in tasks:\n",
    "        df.loc[df.exc_num==task, 'inverted'] = 1\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def set_difficulty(df, def_cols=['v_angle', 'v_sd', 'torque_xy_avg'], levels=[20, 20, 20]):\n",
    "    if levels is not None:\n",
    "        for col, level in zip(def_cols, levels):\n",
    "            df,_ = ability_level_mapper(df, col=col, n_level=level, target_col_name=col)\n",
    "    df['difficulty'] = 0\n",
    "    cnt = 0\n",
    "    df = df.set_index(def_cols)\n",
    "    for index, group in df.groupby(df.index):\n",
    "#         print(df.loc[index, 'difficulty'])\n",
    "        df.loc[index, 'difficulty'] = cnt\n",
    "        cnt += 1\n",
    "    df = df.reset_index()   \n",
    "    return df\n",
    "\n",
    "def def_env(test_col, diff_def, n_class, group):\n",
    "    \n",
    "    tmp = [test_col, diff_def, n_class, group]\n",
    "    with open('../data/parameter/def_env.p', 'wb') as f:\n",
    "        pickle.dump(tmp, f)\n",
    "        \n",
    "    del tmp\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../data/new_all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clear outlier that recorded in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3264228\n",
      "short length\n",
      "(1, 1.1, 3, 3)\n",
      "short length\n",
      "(1, 1.1, 3, 10)\n",
      "short length\n",
      "(1, 1.2, 1, 3)\n",
      "short length\n",
      "(1, 1.2, 1, 8)\n",
      "short length\n",
      "(1, 1.2, 1, 10)\n",
      "short length\n",
      "(1, 1.2, 1, 11)\n",
      "short length\n",
      "(1, 1.2, 2, 3)\n",
      "short length\n",
      "(1, 1.2, 2, 8)\n",
      "short length\n",
      "(1, 1.2, 2, 10)\n",
      "short length\n",
      "(1, 1.2, 2, 11)\n",
      "short length\n",
      "(1, 1.2, 3, 3)\n",
      "short length\n",
      "(1, 1.2, 3, 8)\n",
      "[1, 1.2, 3, 10]\n",
      "in the outlier list\n",
      "short length\n",
      "(1, 1.2, 3, 11)\n",
      "short length\n",
      "(1, 1.2, 4, 3)\n",
      "short length\n",
      "(1, 1.2, 4, 11)\n",
      "short length\n",
      "(1, 1.2, 5, 3)\n",
      "short length\n",
      "(1, 1.2, 5, 11)\n",
      "short length\n",
      "(1, 1.2, 6, 11)\n",
      "[1, 1.3, 4, 10]\n",
      "in the outlier list\n",
      "[1, 1.3, 6, 8]\n",
      "in the outlier list\n",
      "[1, 1.4, 2, 3]\n",
      "in the outlier list\n",
      "short length\n",
      "(2, 1.1, 1, 1)\n",
      "short length\n",
      "(2, 1.1, 1, 2)\n",
      "short length\n",
      "(2, 1.1, 1, 3)\n",
      "short length\n",
      "(2, 1.1, 1, 4)\n",
      "short length\n",
      "(2, 1.1, 1, 5)\n",
      "[2, 1.1, 1, 6]\n",
      "in the outlier list\n",
      "short length\n",
      "(2, 1.1, 1, 8)\n",
      "short length\n",
      "(2, 1.1, 2, 1)\n",
      "short length\n",
      "(2, 1.1, 2, 6)\n",
      "short length\n",
      "(2, 1.1, 2, 8)\n",
      "short length\n",
      "(2, 1.1, 3, 6)\n",
      "short length\n",
      "(2, 1.2, 1, 1)\n",
      "short length\n",
      "(2, 1.2, 1, 2)\n",
      "short length\n",
      "(2, 1.2, 1, 3)\n",
      "short length\n",
      "(2, 1.2, 1, 4)\n",
      "short length\n",
      "(2, 1.2, 1, 5)\n",
      "short length\n",
      "(2, 1.2, 1, 8)\n",
      "short length\n",
      "(2, 1.2, 2, 1)\n",
      "short length\n",
      "(2, 1.2, 3, 1)\n",
      "[2, 1.3, 1, 4]\n",
      "in the outlier list\n",
      "[2, 1.5, 1, 5]\n",
      "in the outlier list\n",
      "[2, 2.1, 2, 10]\n",
      "in the outlier list\n",
      "[2, 2.2, 2, 2]\n",
      "in the outlier list\n",
      "[2, 2.3, 2, 6]\n",
      "in the outlier list\n",
      "[2, 2.3, 3, 2]\n",
      "in the outlier list\n",
      "[3, 2.1, 1, 5]\n",
      "in the outlier list\n",
      "[3, 2.3, 1, 2]\n",
      "in the outlier list\n",
      "[3, 2.3, 1, 11]\n",
      "in the outlier list\n",
      "[3, 2.3, 2, 11]\n",
      "in the outlier list\n",
      "[3, 3.1, 1, 2]\n",
      "in the outlier list\n",
      "[3, 3.1, 2, 2]\n",
      "in the outlier list\n",
      "[3, 3.1, 3, 2]\n",
      "in the outlier list\n",
      "[3, 3.1, 3, 5]\n",
      "in the outlier list\n",
      "[3, 3.1, 4, 2]\n",
      "in the outlier list\n",
      "[3, 3.1, 4, 5]\n",
      "in the outlier list\n",
      "[3, 3.1, 5, 5]\n",
      "in the outlier list\n",
      "[3, 3.2, 2, 2]\n",
      "in the outlier list\n",
      "[3, 3.2, 2, 5]\n",
      "in the outlier list\n",
      "[3, 3.2, 3, 3]\n",
      "in the outlier list\n",
      "[4, 3.1, 1, 5]\n",
      "in the outlier list\n",
      "[4, 3.1, 2, 1]\n",
      "in the outlier list\n",
      "[4, 4.2, 2, 2]\n",
      "in the outlier list\n",
      "[4, 4.2, 5, 8]\n",
      "in the outlier list\n",
      "[4, 4.3, 1, 4]\n",
      "in the outlier list\n",
      "[4, 4.3, 1, 6]\n",
      "in the outlier list\n",
      "short length\n",
      "(4, 4.3, 1, 10)\n",
      "[4, 4.3, 2, 3]\n",
      "in the outlier list\n",
      "[4, 4.3, 2, 4]\n",
      "in the outlier list\n",
      "short length\n",
      "(4, 4.3, 2, 10)\n",
      "[4, 4.3, 3, 8]\n",
      "in the outlier list\n",
      "short length\n",
      "(4, 4.3, 3, 10)\n",
      "[4, 4.3, 6, 7]\n",
      "in the outlier list\n",
      "[5, 2.3, 1, 7]\n",
      "in the outlier list\n",
      "short length\n",
      "(5, 4.1, 2, 6)\n",
      "short length\n",
      "(5, 4.2, 2, 6)\n",
      "[5, 4.3, 1, 4]\n",
      "in the outlier list\n",
      "[5, 4.3, 2, 6]\n",
      "in the outlier list\n",
      "[5, 4.3, 2, 10]\n",
      "in the outlier list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2979058"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_data))\n",
    "outliers = []\n",
    "\n",
    "with open('../data/deviation_curves_outlier.csv') as f:\n",
    "    for line in f.readlines():\n",
    "        tmp = line.split('\\n')[0].split(' ')\n",
    "       \n",
    "        outliers.append([float(x) for x in tmp])\n",
    "        \n",
    "groups = all_data.set_index(['day', 'exc_num', 'exc_times', 'uid'])\n",
    "groups = groups.groupby(by=groups.index)\n",
    "\n",
    "new_data = pd.DataFrame()\n",
    "\n",
    "for index, group in groups:\n",
    "    if len(group)<10:\n",
    "        print('short length')\n",
    "        print(index)\n",
    "        continue\n",
    "    day, exc_num, exc_times, uid = index\n",
    "    exc_num = round(exc_num, 1)\n",
    "    if [day, exc_num, exc_times, uid] in outliers:\n",
    "        print([day, exc_num, exc_times, uid])\n",
    "        print('in the outlier list')\n",
    "        pass\n",
    "#         tmp = group.reset_index()\n",
    "#         sns.set_style('whitegrid')\n",
    "#         f, ax= plt.subplots(figsize = (14, 10))\n",
    "#         ax = sns.lineplot(x=tmp.index, y=\"front\", data=tmp)\n",
    "#         ax.set_title(index) \n",
    "    else:\n",
    "        curr = group.reset_index()\n",
    "        new_data = pd.concat([new_data, curr], axis=0)\n",
    "all_data = new_data\n",
    "del new_data\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/step1_clear_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_velocity(df, interval=20):\n",
    "    if 'velocity' not in df.columns:\n",
    "        df = calc_velocity(df)\n",
    "        \n",
    "    df['avg_velocity'] = df['velocity'].rolling(interval, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def find_forwards_segment(df, exc=1.1, rotation_threshold=1, new_num=0.1):\n",
    "    assert exc is not None, 'rewrite function find_forwards_segment first'\n",
    "    tmp = df[df['exc_num']==exc]\n",
    "    tmp = tmp.loc[(tmp.Lx>0) & ((tmp.Az<rotation_threshold) | (tmp.Az>-rotation_threshold))]\n",
    "    tmp['exc_num'] = new_num\n",
    "    df = pd.concat([df, tmp])\n",
    "    df = df.reset_index(drop=True)\n",
    "    del tmp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = calc_avg_velocity(df)\n",
    "# # df = find_forwards_segment(df)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/step1_clear_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load precleared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "test_col = 'front'\n",
    "diff_def = ['v_angle', 'v_sd', 'torque_xy_avg', 'inverted']\n",
    "n_class = [10, 10, 5, 2]\n",
    "group = ['day', 'uid', 'exc_num', 'exc_times']+[test_col]\n",
    "def_env(test_col, diff_def, n_class, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\n",
      "2813427\n",
      "2813427\n",
      "sd\n",
      "2813427\n",
      "2800469\n",
      "torque\n",
      "2813427\n",
      "2745909\n",
      "main\n",
      "2745909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2845: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  return runner(coro)\n",
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_data = all_data.drop(['left', 'right'], axis=1)\n",
    "all_data = all_data[(all_data['Fx.1']==0) & (all_data['Fy.1']==0) & (all_data['Fz.1']==0)].reset_index(drop=True)\n",
    "# all_data = calc_force(all_data)\n",
    "print('main')\n",
    "print(len(all_data))\n",
    "print(len(all_data.dropna()))\n",
    "# all_data = calc_velocity(all_data)\n",
    "# all_data = calc_resultent_force(all_data)\n",
    "# all_data = calc_resultent_force_xy(all_data)\n",
    "# all_data = calc_velocity_xy(all_data)\n",
    "# all_data = calc_force_velocity_angle_xy(all_data)\n",
    "# all_data = calc_abs_force_velocity_angle_xy(all_data)\n",
    "# all_data = calc_torque_xy(all_data)\n",
    "# all_data = calc_torque_turning_freq(all_data)\n",
    "all_data = calc_velocity_angle(all_data)\n",
    "all_data = calc_sd_velocity(all_data, dropna=False)\n",
    "all_data = calc_torque_xy_avg(all_data, dropna=False)\n",
    "all_data = calc_avg_velocity(all_data)\n",
    "all_data = calc_velocity_deviation_score(all_data, a=0.01)\n",
    "all_data = all_data.dropna()\n",
    "print('main')\n",
    "print(len(all_data))\n",
    "all_data = set_inverted_task(all_data)\n",
    "# # all_data = set_difficulty(all_data, def_cols=['v_angle', 'v_sd', 'torque_xy_avg'], levels=[20, 20, 20])\n",
    "all_data,_ = ability_level_mapper(all_data, col='v_angle', n_level=10, target_col_name='v_angle', invert=False)\n",
    "all_data,_ = ability_level_mapper(all_data, col='torque_xy_avg', \n",
    "                                  n_level=10, target_col_name='torque_xy_avg', invert=False)\n",
    "all_data,_ = ability_level_mapper(all_data, col='v_sd', n_level=5, target_col_name='v_sd', invert=False)\n",
    "all_data = set_difficulty(all_data, def_cols=diff_def, levels=None)\n",
    "\n",
    "# # all_data = calc_angle_rotation_velocity_xy(all_data)\n",
    "# # all_data = calc_abs_angle_rotation_velocity_xy(all_data)\n",
    "# # all_data = all_data[['day', 'uid', 'exc_num', 'exc_times', 'velocity', 'force', 'front', 'torque_xy', \\\n",
    "# #                     'resultent_force', 'resultent_force_xy', 'velocity_xy', 'angle_fv_xy', 'abs_angle_fv_xy', \\\n",
    "# #                     'tt_freq', 'v_rotation']]\n",
    "\n",
    "all_data = all_data[['day', 'uid', 'exc_num', 'exc_times', 'avg_velocity', 'front', 'difficulty', 'vd_score']]\n",
    "all_data = del_outlier(all_data, \n",
    "            ['difficulty', 'uid', 'day', 'exc_num', 'exc_times'], \n",
    "            test_col='avg_velocity')\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "# groups = all_data[all_data['exc_num'] == 1.1].groupby(['day', 'uid', 'exc_num', 'exc_times'])\n",
    "# all_data.head()\n",
    "# len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>uid</th>\n",
       "      <th>exc_num</th>\n",
       "      <th>exc_times</th>\n",
       "      <th>avg_velocity</th>\n",
       "      <th>front</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>vd_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261413</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>113</td>\n",
       "      <td>16.484623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.256533</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>113</td>\n",
       "      <td>16.176885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251974</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>113</td>\n",
       "      <td>14.876719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247416</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>113</td>\n",
       "      <td>14.607577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243323</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>113</td>\n",
       "      <td>14.365961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  uid  exc_num  exc_times  avg_velocity     front  difficulty   vd_score\n",
       "0    1    4      1.1          1      0.261413  0.005858         113  16.484623\n",
       "1    1    4      1.1          1      0.256533  0.005858         113  16.176885\n",
       "2    1    4      1.1          1      0.251974  0.006937         113  14.876719\n",
       "3    1    4      1.1          1      0.247416  0.006937         113  14.607577\n",
       "4    1    4      1.1          1      0.243323  0.006937         113  14.365961"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tmp = all_data[all_data.v_angle>3.1]\n",
    "# tmp = all_data.loc[((all_data.uid==1) | (all_data.uid==3)) & ((all_data.exc_num==1.3) | (all_data.exc_num==2.3) | \n",
    "#                                                              (all_data.exc_num==1.1))]\n",
    "# sns.set_style('whitegrid')\n",
    "# f, ax= plt.subplots(figsize = (14, 10))\n",
    "# ax = sns.violinplot(x=\"exc_num\", y='v_angle', hue='uid', data=tmp)\n",
    "\n",
    "# tmp = all_data.loc[((all_data.uid==1) | (all_data.uid==11)) & ((all_data.exc_num==1.3) | (all_data.exc_num==2.3) | \n",
    "#                                                              (all_data.exc_num==1.1))]\n",
    "# sns.set_style('whitegrid')\n",
    "# f, ax= plt.subplots(figsize = (14, 10))\n",
    "# ax = sns.violinplot(x=\"exc_num\", y='v_angle', hue='uid', data=tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # del tmp\n",
    "# # tmp = all_data.copy()\n",
    "# tmp = all_data.loc[#((all_data.uid==2) | (all_data.uid==6)) \n",
    "#                     (all_data.day==2) \n",
    "# #                    & (all_data.exc_num==1.3) \n",
    "# #                    & (all_data.exc_times==1)\n",
    "#                   ]\n",
    "# cnt = 0\n",
    "# by_cols = ['v_angle', 'v_sd',\n",
    "#            'torque_xy_avg', 'inverted', 'day', 'exc_num', 'exc_times'\n",
    "#           ]\n",
    "# for index,group in tmp.groupby(by_cols):\n",
    "    \n",
    "#     if len(group)<100 or len(group['uid'].unique())<8:\n",
    "#         continue\n",
    "#     print(len(group))\n",
    "#     cnt += 1\n",
    "#     if cnt>10: continue\n",
    "#     group = group.reset_index()\n",
    "#     sns.set_style('whitegrid')\n",
    "#     f, ax= plt.subplots(figsize = (14, 10))\n",
    "#     ax = sns.violinplot(x=\"v_angle\", y='velocity', hue='uid', data=group)\n",
    "#     ax.set_title(index)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tmp = all_data.loc[((all_data.uid==2)) & (all_data.v_angle==4) & (all_data.v_sd==6) & (all_data.torque_xy==6)\n",
    "#                    & (all_data.day==1) & (all_data.exc_num==1.3) & (all_data.exc_times==1)]\n",
    "# sns.set_style('whitegrid')\n",
    "# f, ax= plt.subplots(figsize = (14, 10))\n",
    "# ax = sns.lineplot(x=tmp.index, y='velocity', data=tmp)\n",
    "\n",
    "# tmp = all_data.loc[((all_data.uid==2)) \n",
    "#                    & (all_data.day==1) & (all_data.exc_num==1.3) & (all_data.exc_times==1)]\n",
    "# sns.set_style('whitegrid')\n",
    "# f, ax= plt.subplots(figsize = (14, 10))\n",
    "# ax = sns.lineplot(x=tmp.index, y='velocity', data=tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # parameters\n",
    "# target_col = 'velocity'\n",
    "# target_exc = None\n",
    "# cnt = 0\n",
    "\n",
    "\n",
    "# if target_exc is None:\n",
    "#     groups = all_data[['day', 'uid', 'exc_num', 'exc_times', target_col]].groupby(['day', 'uid', 'exc_num', 'exc_times'])\n",
    "# else:\n",
    "#     tmp = all_data[all_data['exc_num']==target_exc]\n",
    "#     assert len(tmp)>10, 'empty data'\n",
    "#     groups = tmp[['day', 'uid', 'exc_num', 'exc_times', target_col]].groupby(['day', 'uid', 'exc_num', 'exc_times'])\n",
    "#     del tmp\n",
    "\n",
    "\n",
    "\n",
    "# for index, group in groups:\n",
    "#     if cnt>10:\n",
    "#         break\n",
    "#     cnt += 1\n",
    "    \n",
    "# #     print(index)\n",
    "#     tmp = group.reset_index(drop=True)\n",
    "#     tmp = tmp.reset_index()\n",
    "# #     print(group)\n",
    "#     sns.set_style('whitegrid')\n",
    "#     f, ax= plt.subplots(figsize = (14, 10))\n",
    "#     ax = sns.lineplot(x=\"index\", y=target_col, data=tmp)\n",
    "#     ax.set_title(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce initial deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_header(data, head=500, has_tail=False):\n",
    "    \n",
    "    groups = data.set_index(['day', 'exc_num', 'exc_times', 'uid'])\n",
    "    groups = groups.groupby(groups.index)\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for index, group in groups:\n",
    "        \n",
    "        if has_tail:\n",
    "            assert len(group)>(head*2), 'outlier'\n",
    "        else:\n",
    "            assert len(group)>head, 'outlier'\n",
    "            \n",
    "        header = [i+1 for i in xrange(head)]\n",
    "        if has_tail:\n",
    "            tailer = header[::-1]\n",
    "            middle = [head for i in xrange(len(group)-head*2)]\n",
    "            weights = header+middle+tailer\n",
    "\n",
    "        else:\n",
    "            middle = [head for i in xrange(len(group)-head)]\n",
    "\n",
    "            weights = header+middle\n",
    "            \n",
    "        weights = pd.Series(weights)    \n",
    "        weights = weights/head\n",
    "        assert len(group)==len(weights), 'different length between group and weights'\n",
    "        curr = group.reset_index()\n",
    "        curr['front'] =curr['front']*weights\n",
    "        result = pd.concat([result, curr])\n",
    "        del curr\n",
    "        \n",
    "    return result.reset_index(drop=True)\n",
    "                            \n",
    "\n",
    "# new_data = reduce_header(new_data,  head=300, has_tail=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8cd2b35ae203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(new_data))\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('../data/step1_clear_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
